<!--
  ~ Smart Data Lake - Build your data lake the smart way.
  ~
  ~ Copyright Â© 2019-2020 ELCA Informatique SA (<https://www.elca.ch>)
  ~
  ~ This program is free software: you can redistribute it and/or modify
  ~ it under the terms of the GNU General Public License as published by
  ~ the Free Software Foundation, either version 3 of the License, or
  ~ (at your option) any later version.
  ~
  ~ This program is distributed in the hope that it will be useful,
  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of
  ~ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  ~ GNU General Public License for more details.
  ~
  ~ You should have received a copy of the GNU General Public License
  ~ along with this program. If not, see <http://www.gnu.org/licenses/>.
  -->
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>io.smartdatalake</groupId>
	<artifactId>sdl-parent</artifactId>
	<version>2.0.0-SNAPSHOT</version>
	<packaging>pom</packaging>

	<modules>
		<module>sdl-core</module>
		<module>sdl-kafka</module>
		<module>sdl-splunk</module>
		<module>sdl-jms</module>
	</modules>

	<licenses>
		<license>
			<name>GNU General Public License (GPL) version 3</name>
			<url>https://www.gnu.org/licenses/gpl-3.0.html</url>
		</license>
	</licenses>

	<!-- Used for license header by maven-license-plugin -->
	<name>Smart Data Lake</name>
	<description>Build your data lake the smart way.</description>
	<url>http://www.smartdatalake.io</url>
	<inceptionYear>2019</inceptionYear>
	<organization>
		<name>ELCA Informatique SA</name>
		<url>https://www.elca.ch</url>
	</organization>

	<developers>
		<developer>
			<name>Smart Data Lake</name>
			<email>smartdatalake@elca.ch</email>
			<organization>ELCA Informatik AG</organization>
			<organizationUrl>http://www.elca.ch</organizationUrl>
		</developer>
	</developers>

	<profiles>
		<profile>
			<id>fat-jar</id>
			<properties>
				<skip.assembly>false</skip.assembly>
				<scala.deps.scope>provided</scala.deps.scope>
				<spark.deps.scope>provided</spark.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>fat-jar-with-spark</id>
			<properties>
				<skip.assembly>false</skip.assembly>
				<scala.deps.scope>compile</scala.deps.scope>
				<spark.deps.scope>compile</spark.deps.scope>
			</properties>
		</profile>
		<profile>
			<!-- do not use this profile if you want to see warnings about missing links
            it makes sense to check warnings about internal (public) members, but we will always have
            warnings for external libraries which is why we deactivate them -->
			<id>scala-doc-nolinkwarnings</id>
			<properties>
				<noLinkWarnings>-no-link-warnings</noLinkWarnings>
			</properties>
		</profile>
		<!-- only scala 2.12 supported in spark 3.0 -->
		<profile>
			<id>scala-2.12</id>
			<activation><activeByDefault>true</activeByDefault></activation>
			<properties>
				<scala.minor.version>2.12</scala.minor.version>
				<scala.version>${scala.minor.version}.12</scala.version>
			</properties>
		</profile>
		<!-- default is hadoop 2.7 in spark 3.0, to build for hadoop 3 activate this profile -->
		<profile>
			<id>hadoop-3.2</id>
			<properties>
				<hadoop.version>3.2.0</hadoop.version>
				<curator.version>2.13.0</curator.version>
			</properties>
		</profile>
	</profiles>

	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<skip.assembly>true</skip.assembly>
		<noLinkWarnings>-unchecked</noLinkWarnings>
		<license.header.file>src/license/gplv3-header.txt</license.header.file>

		<maven.compiler.source>1.8</maven.compiler.source>
		<maven.compiler.target>1.8</maven.compiler.target>
		<maven.compiler.release>8</maven.compiler.release>

		<scala.deps.scope>compile</scala.deps.scope>
		<spark.deps.scope>compile</spark.deps.scope>

		<spark.version>3.0.1</spark.version>

		<!-- SPARK-PARENT start: properties copied from spark-parent pom version 2.4.7 for spark-parent import in dependencyManagement -->
		<!-- attention - manually adapted are: zookeeper, scala.version, scala.binary.version -->
		<slf4j.version>1.7.30</slf4j.version>
		<log4j.version>1.2.17</log4j.version>
		<!-- hadoop version must match the hadoop version included by spark-core -->
		<!-- could be better to use cloudera version of hadoop because they backported many bugfixes from later versions -->
		<!--hadoop.version>2.6.0-cdh5.16.1</hadoop.version-->
		<hadoop.version>2.7.4</hadoop.version>
		<protobuf.version>2.5.0</protobuf.version>
		<yarn.version>${hadoop.version}</yarn.version>
		<zookeeper.version>3.4.14</zookeeper.version>
		<curator.version>2.7.1</curator.version>
		<hive.group>org.apache.hive</hive.group>
		<hive.classifier>core</hive.classifier>
		<!--  Version used in Maven Hive dependency  -->
		<hive.version>2.3.7</hive.version>
		<hive23.version>2.3.7</hive23.version>
		<!-- Version used for internal directory structure -->
		<hive.version.short>2.3</hive.version.short>
		<derby.version>10.12.1.1</derby.version>
		<parquet.version>1.10.1</parquet.version>
		<orc.version>1.5.10</orc.version>
		<orc.classifier/>
		<hive.parquet.group>com.twitter</hive.parquet.group>
		<hive.parquet.version>1.6.0</hive.parquet.version>
		<jetty.version>9.4.18.v20190429</jetty.version>
		<javaxservlet.version>3.1.0</javaxservlet.version>
		<chill.version>0.9.5</chill.version>
		<ivy.version>2.4.0</ivy.version>
		<oro.version>2.0.8</oro.version>
		<!--
        If you changes codahale.metrics.version, you also need to change
        the link to metrics.dropwizard.io in docs/monitoring.md.
        -->
		<codahale.metrics.version>4.1.1</codahale.metrics.version>
		<avro.version>1.8.2</avro.version>
		<avro.mapred.classifier>hadoop2</avro.mapred.classifier>
		<aws.kinesis.client.version>1.12.0</aws.kinesis.client.version>
		<!-- Should be consistent with Kinesis client dependency -->
		<aws.java.sdk.version>1.11.655</aws.java.sdk.version>
		<!-- the producer is used in tests -->
		<aws.kinesis.producer.version>0.12.8</aws.kinesis.producer.version>
		<!--  org.apache.httpcomponents/httpclient-->
		<commons.httpclient.version>4.5.6</commons.httpclient.version>
		<commons.httpcore.version>4.4.12</commons.httpcore.version>
		<!--  commons-httpclient/commons-httpclient-->
		<httpclient.classic.version>3.1</httpclient.classic.version>
		<commons.math3.version>3.4.1</commons.math3.version>
		<!-- managed up from 3.2.1 for SPARK-11652 -->
		<commons.collections.version>3.2.2</commons.collections.version>
		<scala.binary.version>${scala.minor.version}</scala.binary.version>
		<scalatest-maven-plugin.version>2.0.0</scalatest-maven-plugin.version>
		<scalafmt.parameters>--test</scalafmt.parameters>
		<!-- for now, not running scalafmt as part of default verify pipeline -->
		<scalafmt.skip>true</scalafmt.skip>
		<codehaus.jackson.version>1.9.13</codehaus.jackson.version>
		<fasterxml.jackson.version>2.10.0</fasterxml.jackson.version>
		<snappy.version>1.1.7.5</snappy.version>
		<netlib.java.version>1.1.2</netlib.java.version>
		<commons-codec.version>1.10</commons-codec.version>
		<commons-io.version>2.4</commons-io.version>
		<!-- org.apache.commons/commons-lang/-->
		<commons-lang2.version>2.6</commons-lang2.version>
		<!-- org.apache.commons/commons-lang3/-->
		<commons-lang3.version>3.9</commons-lang3.version>
		<!-- org.apache.commons/commons-pool2/-->
		<commons-pool2.version>2.6.2</commons-pool2.version>
		<datanucleus-core.version>4.1.17</datanucleus-core.version>
		<guava.version>14.0.1</guava.version>
		<janino.version>3.0.16</janino.version>
		<jersey.version>2.30</jersey.version>
		<joda.version>2.10.5</joda.version>
		<jodd.version>3.5.2</jodd.version>
		<jsr305.version>3.0.0</jsr305.version>
		<libthrift.version>0.12.0</libthrift.version>
		<antlr4.version>4.7.1</antlr4.version>
		<jpam.version>1.1</jpam.version>
		<selenium.version>2.52.0</selenium.version>
		<htmlunit.version>2.22</htmlunit.version>
		<!--
        Managed up from older version from Avro; sync with jackson-module-paranamer dependency version
        -->
		<paranamer.version>2.8</paranamer.version>
		<maven-antrun.version>1.8</maven-antrun.version>
		<commons-crypto.version>1.0.0</commons-crypto.version>
		<!--
        If you are changing Arrow version specification, please check ./python/pyspark/sql/utils.py,
        and ./python/setup.py too.
        -->
		<arrow.version>0.15.1</arrow.version>
		<!-- org.fusesource.leveldbjni will be used except on arm64 platform. -->
		<leveldbjni.group>org.fusesource.leveldbjni</leveldbjni.group>
		<!-- SPARK-PARENT finished -->


		<!-- other dependency versions -->
		<scopt.version>3.7.1</scopt.version>
		<databricks.spark-xml.version>0.9.0</databricks.spark-xml.version>
		<spark.excel.version>0.12.0</spark.excel.version>
		<ucanaccess.version>4.0.4</ucanaccess.version>
		<!-- when changing config version, remember to update it in DatabricksSmartDataLakeBuilder main method -->
		<typesafe.config.version>1.3.4</typesafe.config.version>
		<monix.version>3.1.0</monix.version>
		<scala-arm.version>2.0</scala-arm.version>
		<splunk.version>1.6.5.0</splunk.version>
		<sshj.version>0.21.1</sshj.version>
		<kafka.version>2.4.1</kafka.version>
		<keycloak.version>4.5.0.Final</keycloak.version>
		<deltaTable.version>0.7.0</deltaTable.version>
		<poi.version>4.0.0</poi.version>

		<scalatest.test.version>3.0.1</scalatest.test.version>
		<sshd.test.version>2.3.0</sshd.test.version>

	</properties>

	<distributionManagement>
		<repository>
			<id>bintray-smart-data-lake-smart-data-lake</id>
			<name>smart-data-lake-smart-data-lake</name>
			<url>https://api.bintray.com/maven/smart-data-lake/smart-data-lake/smart-data-lake/;publish=1</url>
		</repository>
	</distributionManagement>

	<scm>
		<connection>scm:git:git://github.com/smart-data-lake/smart-data-lake.git</connection>
		<developerConnection>scm:git:ssh://github.com/smart-data-lake/smart-data-lake.git</developerConnection>
		<url>http://github.com/smart-data-lake/smart-data-lake/tree/master</url>
	</scm>

	<repositories>
		<repository>
			<id>spring-plugins</id>
			<name>Spring Plugins Repository</name>
			<url>https://repo.spring.io/plugins-release/</url>
		</repository>
		<repository>
			<id>confluent</id>
			<name>Confluent Schema  Repository</name>
			<url>https://packages.confluent.io/maven/</url>
		</repository>
	</repositories>

	<build>

		<pluginManagement>
			<plugins>
				<!-- Compiles Scala sources. -->
				<plugin>
					<groupId>net.alchim31.maven</groupId>
					<artifactId>scala-maven-plugin</artifactId>
					<version>4.3.1</version>
					<executions>
						<execution>
							<goals>
								<goal>compile</goal>
								<goal>testCompile</goal>
							</goals>
						</execution>
					</executions>
					<configuration>
						<scalaCompatVersion>${scala.minor.version}</scalaCompatVersion>
						<checkMultipleScalaVersions>true</checkMultipleScalaVersions>
						<failOnMultipleScalaVersions>true</failOnMultipleScalaVersions>
						<recompileMode>incremental</recompileMode>
						<args>
							<arg>-unchecked</arg>
							<arg>-deprecation</arg>
							<arg>-feature</arg>
							<arg>-explaintypes</arg>
							<arg>-target:jvm-1.8</arg>
							<arg>${noLinkWarnings}</arg>
						</args>
						<jvmArgs>
							<jvmArg>-Xms64m</jvmArg>
							<jvmArg>-Xmx1024m</jvmArg>
						</jvmArgs>
					</configuration>
				</plugin>

				<!-- rewrite pom for compiling with different scala version profiles -->
				<plugin>
					<groupId>org.spurint.maven.plugins</groupId>
					<artifactId>scala-cross-maven-plugin</artifactId>
					<version>0.2.1</version>
					<executions>
						<execution>
							<id>rewrite-pom</id>
							<goals>
								<goal>rewrite-pom</goal>
							</goals>
						</execution>
					</executions>
				</plugin>

				<!-- Copies files in resources folders to target folder. -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-resources-plugin</artifactId>
					<version>3.1.0</version>
				</plugin>

				<!-- Checks whether source files have the specified license header. -->
				<plugin>
					<groupId>com.mycila</groupId>
					<artifactId>license-maven-plugin</artifactId>
					<version>3.0</version>
					<configuration>
						<header>${basedir}/${license.header.file}</header>
						<properties>
							<copyright.name>${project.organization.name}</copyright.name>
							<copyright.contact>${project.organization.url}</copyright.contact>
						</properties>
						<includes>
							<include>src/**</include>
						</includes>
						<excludes>
							<exclude>**/*.accdb</exclude>
							<exclude>**/*.mdb</exclude>
							<exclude>**/*.csv</exclude>
							<exclude>**/*.keytab</exclude>
							<exclude>**/*.pkcs12</exclude>
						</excludes>
						<mapping>
							<scala>SLASHSTAR_STYLE</scala>
							<conf>SCRIPT_STYLE</conf>
						</mapping>
						<failIfMissing>false</failIfMissing>
					</configuration>
					<dependencies>
						<dependency>
							<groupId>com.mycila</groupId>
							<artifactId>license-maven-plugin-git</artifactId>
							<version>3.0</version>
						</dependency>
					</dependencies>
					<executions>
						<execution>
							<goals>
								<goal>check</goal>
							</goals>
						</execution>
					</executions>
				</plugin>

				<!-- Creates the jar without dependencies -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-jar-plugin</artifactId>
					<version>3.1.2</version>
					<configuration>
						<archive>
							<manifest>
								<addClasspath>true</addClasspath>
								<mainClass>io.smartdatalake.app.LocalSmartDataLakeBuilder</mainClass>
							</manifest>
							<manifestEntries>
								<Implementation-Version>${project.version}</Implementation-Version>
							</manifestEntries>
						</archive>
						<excludes>
							<exclude>log4j.properties</exclude> <!-- Logging configuration should be left to user. -->
							<exclude>${project.artifactId}*.jar</exclude> <!-- avoid "Error assembling JAR" because of already existing artifact jar -->
						</excludes>
					</configuration>
				</plugin>

				<!-- Creates a JAR file with the source files of the project. -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-source-plugin</artifactId>
					<version>3.1.0</version>
					<executions>
						<execution>
							<id>attach-sources</id>
							<goals>
								<goal>jar-no-fork</goal>
							</goals>
						</execution>
					</executions>
					<configuration>
						<excludes>
							<exclude>log4j.properties</exclude> <!-- Logging configuration source should not be distributed. -->
						</excludes>
					</configuration>
				</plugin>

				<!-- Builds executable fat-jar that includes all dependencies -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-assembly-plugin</artifactId>
					<version>3.1.1</version>
					<configuration>
						<descriptorRefs>
							<descriptorRef>jar-with-dependencies</descriptorRef>
						</descriptorRefs>
						<archive>
							<manifest>
								<mainClass>io.smartdatalake.app.LocalSmartDataLakeBuilder</mainClass>
							</manifest>
							<manifestEntries>
								<Implementation-Version>${project.version}</Implementation-Version>
							</manifestEntries>
						</archive>
						<skipAssembly>${skip.assembly}</skipAssembly>
					</configuration>
					<executions>
						<execution>
							<id>make-assembly</id>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
						</execution>
					</executions>
				</plugin>

				<!-- Executes units tests with scalatest  -->
				<plugin>
					<groupId>org.scalatest</groupId>
					<artifactId>scalatest-maven-plugin</artifactId>
					<version>2.0.0</version>
					<configuration>
						<reportsDirectory>
							${project.build.directory}/scalatest-reports
						</reportsDirectory>
						<junitxml>.</junitxml>
						<filereports>
							${project.artifactId}.txt
						</filereports>
						<stdout>WT</stdout>  <!-- without color, show reminder of failed and canceled tests with short stack traces, see: http://www.scalatest.org/user_guide/using_scalatest_with_sbt-->
						<environmentVariables>
							<SPARK_LOCAL_IP>127.0.0.1</SPARK_LOCAL_IP> <!-- Suppresses Spark IP discovery during tests (when executed with mvn test) -->
						</environmentVariables>
					</configuration>
					<executions>
						<execution>
							<goals>
								<goal>test</goal>
							</goals>
						</execution>
					</executions>
				</plugin>

				<!-- Checks for declared but unused and undeclared but used dependencies in the verify stage -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-dependency-plugin</artifactId>
					<version>3.1.1</version>
					<configuration>
						<failOnWarning>false</failOnWarning>
						<ignoreNonCompile>true</ignoreNonCompile>
						<ignoredUsedUndeclaredDependencies>
							<dependency>org.scalacheck:scalacheck_${scala.minor.version}</dependency>
						</ignoredUsedUndeclaredDependencies>
					</configuration>
					<executions>
						<execution>
							<goals>
								<goal>analyze-only</goal>
							</goals>
						</execution>
					</executions>
				</plugin>

				<!-- check for dependency version conflicts -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-enforcer-plugin</artifactId>
					<version>3.0.0-M3</version>
					<configuration>
						<rules>
							<requireMavenVersion>
								<version>2.0.6</version>
							</requireMavenVersion>
							<requireJavaVersion>
								<version>1.8</version>
							</requireJavaVersion>
							<dependencyConvergence/>
							<requireProperty>
								<property>scala.minor.version</property>
								<message>You must setscala.minor.version property by activating profile scala-2.11 or scala-2.12!</message>
							</requireProperty>
						</rules>
					</configuration>
				</plugin>

			</plugins>
		</pluginManagement>

		<plugins>

			<!-- Allows handling of version numbers -->
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>versions-maven-plugin</artifactId>
				<version>2.7</version>
			</plugin>

			<!-- disable executing surefire tests as we use scalatest -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
				<version>2.12.4</version>
				<configuration>
					<skip>true</skip>
				</configuration>
			</plugin>

		</plugins>

	</build>

	<!-- cleanup version of conflicting transitive dependencies reported by mvn enforcer:enforce -->
	<dependencyManagement>
		<dependencies>
			<!-- import of SPARK-PARENT pom dependency management to cleanup spark dependencies -->
			<dependency>
				<groupId>org.apache.spark</groupId>
				<artifactId>spark-parent_${scala.minor.version}</artifactId>
				<version>${spark.version}</version>
				<type>pom</type>
				<scope>import</scope>
			</dependency>
			<dependency>
				<groupId>commons-logging</groupId>
				<artifactId>commons-logging</artifactId>
				<version>1.1.3</version>
			</dependency>
			<dependency>
				<groupId>org.apache.commons</groupId>
				<artifactId>commons-compress</artifactId>
				<version>1.4.1</version>
			</dependency>
			<dependency>
				<groupId>io.swagger</groupId>
				<artifactId>swagger-annotations</artifactId>
				<version>1.5.22</version>
			</dependency>
			<dependency>
				<groupId>org.antlr</groupId>
				<artifactId>ST4</artifactId>
				<version>4.0.4</version>
			</dependency>
			<dependency>
				<groupId>org.antlr</groupId>
				<artifactId>antlr-runtime</artifactId>
				<version>3.4</version>
			</dependency>
			<dependency>
				<groupId>org.tukaani</groupId>
				<artifactId>xz</artifactId>
				<version>1.5</version>
			</dependency>
			<dependency>
				<groupId>org.scala-lang.modules</groupId>
				<artifactId>scala-xml_${scala.minor.version}</artifactId>
				<version>1.0.6</version>
				<scope>${scala.deps.scope}</scope>
			</dependency>
			<dependency>
				<groupId>com.google.guava</groupId>
				<artifactId>guava</artifactId>
				<scope>${spark.deps.scope}</scope>
			</dependency>
			<!-- adapt zookeeper version for sdl-kafka -->
			<dependency>
				<groupId>org.apache.zookeeper</groupId>
				<artifactId>zookeeper</artifactId>
				<version>${zookeeper.version}</version>
			</dependency>
			<!-- fix scala.version not properly replaced when importing from spark-parent and override scope -->
			<dependency>
				<groupId>org.scala-lang</groupId>
				<artifactId>scala-compiler</artifactId>
				<version>${scala.version}</version>
				<scope>${scala.deps.scope}</scope>
			</dependency>
			<dependency>
				<groupId>org.scala-lang</groupId>
				<artifactId>scala-reflect</artifactId>
				<version>${scala.version}</version>
				<scope>${scala.deps.scope}</scope>
			</dependency>
			<dependency>
				<groupId>org.scala-lang</groupId>
				<artifactId>scala-library</artifactId>
				<version>${scala.version}</version>
				<scope>${scala.deps.scope}</scope>
			</dependency>
			<dependency>
				<groupId>org.scala-lang</groupId>
				<artifactId>scala-actors</artifactId>
				<version>${scala.version}</version>
				<scope>${scala.deps.scope}</scope>
			</dependency>

			<!-- TEST dependencies -->
			<dependency>
				<groupId>org.scalatest</groupId>
				<artifactId>scalatest_${scala.minor.version}</artifactId>
				<version>${scalatest.test.version}</version>
				<scope>test</scope>
				<exclusions>
					<exclusion>
						<groupId>org.scala-lang.modules</groupId>
						<artifactId>scala-xml_${scala.minor.version}</artifactId>
					</exclusion>
				</exclusions>
			</dependency>
			<dependency>
				<groupId>org.scalactic</groupId>
				<artifactId>scalactic_${scala.minor.version}</artifactId>
				<version>${scalatest.test.version}</version>
				<scope>test</scope>
			</dependency>
			<dependency>
				<groupId>org.scalacheck</groupId>
				<artifactId>scalacheck_${scala.minor.version}</artifactId>
				<version>1.14.3</version>
				<scope>test</scope>
			</dependency>
		</dependencies>
	</dependencyManagement>
</project>
